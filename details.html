<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/swiper/swiper-bundle.min.css"/>
  <link rel="stylesheet" href="detail.css">
  <title>WIRIN-RVCE-details</title>
</head>

<body>
  <!-- Header -->
  <section id="header">
    <div class="header container">
      <div class="nav-bar">
        <div class="brand">
          <a href="#hero">
            <h1>WIRIN</h1>
          </a>
        </div>
        <div class="nav-list">
          <div class="hamburger">
            <div class="bar"></div>
          </div>
          <ul>
            <li><a href="index.html" data-after="Home"><i class = "fa fa-home"></i>   Home</a></li>
              <li><a href="details.html"><i class = "fa fa-clone"></i>   Dataset-details</a></li>
            <li><a href="download.html" data-after="Dataset"><i class = "fa fa-clone"></i>   Dataset</a>
              <div class = "sub_menu" id = "sub_menu">
                  <ul>
                      <li><a href = "details.html">Details</a></li><br>
                      <li><a href = "download.html">Download</a></li>
                  </ul>
              </div>
              </li>
              <li><a href="download.html"><i class = "fa fa-clone"></i>   Dataset-Download</a></li>
            <li><a href="#" data-after="Benchmarks"><i class = "fa fa-bookmark"></i>  Benchmarks</a></li>
            <li><a href="#" data-after="News and Events"><i class = "fa fa-calendar"></i>  News and Events</a></li>
            <li><a href="contacts.html" data-after="Contacts"><i class = "fa fa-phone"></i>  Contacts</a></li>
            <li><a href="login.html" data-after="Login"><i class = "fa fa-user"></i>  Login</a></li>
          </ul>
        </div>
      </div>
    </div>
  </section>
  <!-- End Header -->


  <!-- Hero Section  -->
  <section id="hero">
    <div class="hero container">
      <div>
        <h1>Details <span></span></h1>
      </div>
      <div class = "car_main"><img src="img/car_main5.png"></div>
      <!-- <div class = "car_main"><img src="img/car_main5.png"></div> -->
    </div>
  </section>
  <!-- End Hero Section  -->

  <!-- Contacts section -->

  <section id="contact">
    <div class="contact container">
      <div>
        <h1 class="section-title">Creating National <span>Dataset</span></h1>
        <p>Creating a national dataset of annotated images is a complex task that requires a significant amount of resources and expertise. It's important to have a team with the necessary skills and experience in data collection, annotation, quality control, data management, and distribution. The dataset should be continuously updated and maintained to keep it relevant with the latest environments and conditions.The process typically involves the following steps:</p>
      </div>
      <div class="contact-items">
        <div class="contact-item">
         <div class="icon"><img src="img/Dataset_collection.png" /></div>
          <div class="contact-info">
            <h1>STEP 1: Data collection</h1>
            
           <h2>The first step is to collect a large and diverse set of images that represents the range of environments, conditions, and scenarios that autonomous vehicles are likely to encounter. This may involve using cameras mounted on vehicles, drones, or satellites, or using publicly available datasets. </h2>
            
          </div>
        </div>
        <div class="contact-item">
         <div class="icon"><img src="img/Annotaions.png" /></div>
          <div class="contact-info">
            <h1>STEP 2: Annotation</h1>
            
            
            <h2>Once the images have been collected, they need to be annotated, which means adding labels and tags to the images to provide context and meaning. This can be done manually by human annotators, or automatically using machine learning algorithms. </h2>
            
          </div>
        </div>
        <div class="contact-item">
         <div class="icon"><img src="img/Quality_Control.webp" /></div>
          <div class="contact-info">
            <h1>STEP 3: Quality Control</h1>
            <h2>After the images have been annotated, it's important to check the quality of the annotation to ensure that it is accurate and reliable. This may involve using a combination of manual and tool-based methods. </h2>
          </div>
        </div>
      </div>
      <br>
      <div class="contact-items">
        <div class="contact-item">
          <div class="icon"><img src="img/data management.jpeg" /></div>
          <div class="contact-info">
            <h1>STEP 4: Data Management</h1>
           <h2>Once the dataset is complete, it needs to be managed and stored in a way that makes it accessible and usable for researchers and developers. This may involve using a database management system or a cloud-based storage solution. </h2>
            
          </div>
        </div>
        <div class="contact-item">
        <div class="icon"><img src="img/Distribution.jpg" /></div>
          <div class="contact-info">
            <h1>STEP 5: Distribution</h1>
            <h2>After the dataset is complete and has passed quality control, it needs to be distributed to researchers and developers who will use it to train and test autonomous vehicle systems</h2>
            
          </div>
        </div>
        
      </div>
    </div>
  </section>

  <!-- End of contacts section -->

  <!-- Service Section -->
  <section id="services">
    <div class="services container">
      <div class="service-top">
        <h1 class="section-title">Different Sensors</h1>
        <p>Self-driving cars have the potential to revolutionize the way we think about transportation. They use advanced technologies such as sensors, cameras, and machine learning algorithms to navigate and make decisions on the road. The future of transportation with autonomous vehicles will bring significant changes in terms of safety, efficiency, and convenience.</p>
      </div>
      <div class="service-bottom">
        <div class="service-item">
          <div class="layer"></div>
          <div class="icon"><img src="./img/lidar.jpg" /></div>
          <h2>LIDAR</h2>
          <p>LIDAR sensor uses lasers to measure the distance to objects and create 3D maps of the vehicle's surroundings
        </p><br>
            <a href="https://en.wikipedia.org/wiki/Lidar" class = "card-button" target="_blank">More info</a>
        </div>
        <div class="service-item">
            <div class="layer"></div>
            <div class="icon"><img src="./img/ultrasonic.jpeg" /></div>
            <h2>Ultrasonic</h2>
            <p>Ultrasonic sensors use sound waves to measure the distance to objects and detect obstacles in the vehicle's path.
            </p><br>
              <a href="https://en.wikipedia.org/wiki/Ultrasonic_transducer" class = "card-button" target="_blank">More info</a>
          </div>
          <div class="service-item">
            <div class="layer"></div>
            <div class="icon"><img src="./img/radar.jpeg" /></div>
            <h2>Radar</h2>
            <p>Radars emit radio waves to detect the presence, distance, and speed of objects. They can work in all weather conditions.
            </p><br>
              <a href="https://en.wikipedia.org/wiki/Radar" class = "card-button" target="_blank">More info</a>
          </div>
          <div class="service-item">
            <div class="layer"></div>
            <div class="icon"><img src="./img/gps.jpg" /></div>
            <h2>GPS</h2>>
            <p>Global Positioning System sensors are used to determine the vehicle's location and navigate.
            </p><br>
              <a href="https://en.wikipedia.org/wiki/Global_Positioning_System" class = "card-button" target="_blank">More info</a>
          </div>
          <div class="service-item">
            <div class="layer"></div>
            <div class="icon"><img src="./img/imu.webp" /></div>
            <h2>IMU</h2>
            <p>Inertial Measurement Unit is a device that uses accelerometers and gyroscopes to track the vehicle's orientation and movement.
            </p><br>
              <a href="https://en.wikipedia.org/wiki/Inertial_measurement_unit" class = "card-button" target="_blank">More info</a>
          </div>
          <div class="service-item">
            <div class="layer"></div>
            <div class="icon"><img src="./img/encoder.jpeg" /></div>
            <h2>Wheel encoder</h2>
            <p>Wheel encoder sensors are used to track the rotation of the vehicle's wheels and determine its speed and distance travelled.
            </p><br>
              <a href="https://docs.idew.org/code-robotics/references/physical-inputs/wheel-encoders" class = "card-button" target="_blank">More info</a>
          </div>
      </div>
    </div>
  </section>
  <!-- End Service Section -->

  <!--Types of LIDARS section-->
  <div class="projects-header">
    <h1 class="section-title">Types<span> of</span> LIDARS</h1>
  </div>
  <br><br><br>
  <div id="drag-container">
    <div id="spin-container">
      <!-- Add your images (or video) here -->
      <img src="./img/lidar.jpg" alt="">
      <img src="./img/mechanical lidar.png" alt="">
      <img src="./img/solid state lidar.jpg" alt="">
      <img src="img/flash lidar.png" alt="">
      <img src="img/lidar camera.jpg" alt="">
      <img src="img/multi beam ladar.webp" alt="">
    </div>
    <div id="ground"></div>
  </div>
  
  <div id="music-container"></div>
  <br><br><br><br><br><br><br><br>

<div class="cardlidar">
  
  <div class="card-textlidar">
    <h2>Mechanical LIDAR</h2>
    <p>Mechanical LIDAR uses a spinning mirror to scan the environment and create a 3D point cloud. Mechanical LIDAR sensors are highly accurate, but they can be bulky and expensive.
        <br><br>
    </p>
    <h2> Solid-state LIDAR</h2>
    <p>Solid-state LIDAR uses a static mirror and a laser diode to scan the environment. Solid-state LIDAR sensors are smaller, cheaper and more robust than mechanical Lidar sensors, making them more suitable for automotive applications.
        <br><br>
    </p>
    <h2>Flash LIDAR</h2>
    <p>Flash LIDAR uses a high-powered laser to illuminate the entire field of view at once, creating a 3D point cloud in a single flash. Flash LIDAR sensors are highly accurate, but they are also very expensive and power-hungry
        <br><br>
    </p>
    <h2> LIDAR-Camera Fusion</h2>
    <p>LIDAR-Camera Fusion uses a combination of LIDAR sensor and cameras to provide both depth and color information. It's a cost-effective solution and also provides high-resolution data
        <br><br>
    </p>
    <h2>Multi-beam LIDAR</h2>
    <p>Multi-beam LIDAR uses multiple laser beams to scan the environment, providing a more detailed and accurate 3D point cloud. It's particularly useful for applications such as autonomous vehicles, where high resolution and accuracy are crucial.
        <br><br>
    </p>
  </div>
</div>
  <!-- End types of LIDAR section -->
  <br><br><br><br><br<br>

<!-- Working of a LIDAR video section -->
<section id="video_card">
    <div class="video_card container">
      <div>
        <h1 class="section-title">Working <span>of</span> LIDAR</h1>
        <p style="margin:0 50px; text-align:justify;">A LIDAR sensor typically consists of several main components: a laser, a mirror or lens to direct the laser beam, a detector to capture the reflected laser light, and electronic circuitry to process the data.</p>
        <div class="video_container">
          <video id="myvideo" autoplay muted>
            <source src="img/working of ladar.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </section>
  
  <script>
    var video = document.getElementById("myvideo");
    var observer = new IntersectionObserver(function(entries) {
      if (entries[0].isIntersecting) {
        video.currentTime = 0;
        video.play();
      }
    });
    observer.observe(video);
  </script>
<!-- End of Working of a LIDAR video section -->
<!-- <div>
    <h1 class="section-title">Unleashing the Power of <span>FLIR Cameras</span> and <span>Ouster LIDARs</span> in Autonomous Vehicles</h1>
</div> -->
<!-- FLIR camera -->
<div class="flir-section">
    <img class="flir-img" src="img/flir.png" alt="FLIR Camera">
    <div class="flir-text">
      <h1>FLIR Cameras in Autonomous Vehicles</h1>
      <p>FLIR cameras are thermal imaging cameras that are used in autonomous vehicles to capture images of the surrounding environment. These cameras work by detecting and measuring the infrared radiation emitted by objects in the environment, allowing them to detect and capture images even in low-light or night-time conditions.</p>
      <p>FLIR cameras are particularly useful in autonomous vehicles because they can detect the heat signatures of other vehicles, pedestrians, and animals, even in complete darkness or heavy fog. This allows the vehicle's computer to detect and avoid potential hazards in the environment, even when the visibility is poor. In addition to detecting potential hazards, FLIR cameras can also be used to help the vehicle navigate by detecting and tracking the heat signatures of road markings and traffic signals.</p>
    </div>
  </div>

<!-- FLIR camera ends -->
<!-- Ouster LIDAR -->
<div class="flir-section">
    <img class="flir-img" src="img/outster.png" alt="FLIR Camera">
    <div class="flir-text">
      <h1>Ouster LIDAR in Autonomous Vehicles</h1>
      <p>Ouster's lidar sensors are used in a variety of applications, including self-driving vehicles, industrial automation, security, and mapping. The company's products are known for their high accuracy, long range, and ability to operate in challenging environments.
        Ouster Lidar is a provider of high-resolution, solid-state lidar sensors for applications including self-driving vehicles, industrial automation, security, and mapping</p>
      <p>Their 16-channel sensors offer high density point cloud data, with a field of view of 360 degrees and a maximum range of up to 130 meters. The sensors utilize micro-electromechanical (MEMS) technology, and offer reliable operation in challenging environments. They also have a low power consumption and compact form factor, making them well suited for integration into a wide range of systems.
        Ouster Lidar's sensors use a spinning mechanism to emit laser beams in a 360-degree field of view. This allows them to capture a full, detailed 3D map of the environment in a single sweep. Ouster sensors are also known for their high resolution and accuracy</p>
    </div>
  </div>

<!-- OUSTER Lidar ends -->
  <!-- Footer section -->

  <section id = "entire_footer">
  <hr style="color: rgb(16, 16, 80);">
  <div class="projects-header">
    <h1 class="section-title">Our <span>Team</span></h1>
  </div>
  <footer class="footer">
    <div class="logo-container">
      <img src="img/wipro_correct2.png" alt="logo 2" class="logo">
      <img src="img/iisc_correct.png" alt="logo 3" class="logo">
      <img src="img/rvce_correct.png" alt="logo 1" class="logo">
      <img src="img/nid_correct.png" alt="logo 4" class="logo">
    </div>
    <br><br><br>
  </footer>
  <div class="footer-links">
    <a href="mailto:wirin@rvce.edu.in">Contact Us</a>
    <a href="https://docs.google.com/document/d/1EJlkxEllP2Xn_U6OZWjRUSxULB77M4xt4JRkkfniro8/edit?usp=sharing" target="_blank">Terms and Conditions</a>
    <a href="https://docs.google.com/document/d/1Oh2g50tcgIFOVc85jfqQmcHLMD9ecF_DIDX6hFZc_U0/edit?usp=sharing" target="_blank">Privacy Policy</a>
  </div>
  </section>
  <script src="app.js"></script>
  <!-- Footer section ends -->

</body>

</html>